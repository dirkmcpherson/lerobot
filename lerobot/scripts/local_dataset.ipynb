{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resume: false\n",
      "device: cuda\n",
      "use_amp: false\n",
      "seed: 100000\n",
      "dataset_repo_id: lerobot/pusht\n",
      "video_backend: pyav\n",
      "training:\n",
      "  offline_steps: 200000\n",
      "  num_workers: 4\n",
      "  batch_size: 64\n",
      "  eval_freq: 25000\n",
      "  log_freq: 200\n",
      "  save_checkpoint: true\n",
      "  save_freq: 25000\n",
      "  online_steps: 0\n",
      "  online_rollout_n_episodes: 1\n",
      "  online_rollout_batch_size: 1\n",
      "  online_steps_between_rollouts: 1\n",
      "  online_sampling_ratio: 0.5\n",
      "  online_env_seed: null\n",
      "  online_buffer_capacity: null\n",
      "  online_buffer_seed_size: 0\n",
      "  do_online_rollout_async: false\n",
      "  image_transforms:\n",
      "    enable: false\n",
      "    max_num_transforms: 3\n",
      "    random_order: false\n",
      "    brightness:\n",
      "      weight: 1\n",
      "      min_max:\n",
      "      - 0.8\n",
      "      - 1.2\n",
      "    contrast:\n",
      "      weight: 1\n",
      "      min_max:\n",
      "      - 0.8\n",
      "      - 1.2\n",
      "    saturation:\n",
      "      weight: 1\n",
      "      min_max:\n",
      "      - 0.5\n",
      "      - 1.5\n",
      "    hue:\n",
      "      weight: 1\n",
      "      min_max:\n",
      "      - -0.05\n",
      "      - 0.05\n",
      "    sharpness:\n",
      "      weight: 1\n",
      "      min_max:\n",
      "      - 0.8\n",
      "      - 1.2\n",
      "  grad_clip_norm: 10\n",
      "  lr: 0.0001\n",
      "  lr_scheduler: cosine\n",
      "  lr_warmup_steps: 500\n",
      "  adam_betas:\n",
      "  - 0.95\n",
      "  - 0.999\n",
      "  adam_eps: 1.0e-08\n",
      "  adam_weight_decay: 1.0e-06\n",
      "  delta_timestamps:\n",
      "    observation.image: '[i / ${fps} for i in range(1 - ${policy.n_obs_steps}, 1)]'\n",
      "    observation.state: '[i / ${fps} for i in range(1 - ${policy.n_obs_steps}, 1)]'\n",
      "    action: '[i / ${fps} for i in range(1 - ${policy.n_obs_steps}, 1 - ${policy.n_obs_steps}\n",
      "      + ${policy.horizon})]'\n",
      "  drop_n_last_frames: 7\n",
      "eval:\n",
      "  n_episodes: 50\n",
      "  batch_size: 50\n",
      "  use_async_envs: false\n",
      "wandb:\n",
      "  enable: true\n",
      "  disable_artifact: false\n",
      "  entity: jambotime\n",
      "  project: diffusion_pusht\n",
      "  notes: ''\n",
      "fps: 10\n",
      "env:\n",
      "  name: pusht\n",
      "  task: PushT-v0\n",
      "  image_size: 96\n",
      "  state_dim: 2\n",
      "  action_dim: 2\n",
      "  fps: ${fps}\n",
      "  episode_length: 300\n",
      "  gym:\n",
      "    obs_type: pixels_agent_pos\n",
      "    render_mode: rgb_array\n",
      "    display_cross: false\n",
      "    visualization_width: 384\n",
      "    visualization_height: 384\n",
      "    force_sparse: false\n",
      "override_dataset_stats:\n",
      "  observation.image:\n",
      "    mean:\n",
      "    - - - 0.5\n",
      "    - - - 0.5\n",
      "    - - - 0.5\n",
      "    std:\n",
      "    - - - 0.5\n",
      "    - - - 0.5\n",
      "    - - - 0.5\n",
      "  observation.state:\n",
      "    min:\n",
      "    - 13.456424\n",
      "    - 32.938293\n",
      "    max:\n",
      "    - 496.14618\n",
      "    - 510.9579\n",
      "  action:\n",
      "    min:\n",
      "    - 12.0\n",
      "    - 25.0\n",
      "    max:\n",
      "    - 511.0\n",
      "    - 511.0\n",
      "policy:\n",
      "  name: diffusion\n",
      "  n_obs_steps: 2\n",
      "  horizon: 16\n",
      "  n_action_steps: 8\n",
      "  input_shapes:\n",
      "    observation.image:\n",
      "    - 3\n",
      "    - 64\n",
      "    - 64\n",
      "    observation.state:\n",
      "    - ${env.state_dim}\n",
      "  output_shapes:\n",
      "    action:\n",
      "    - ${env.action_dim}\n",
      "  input_normalization_modes:\n",
      "    observation.image: mean_std\n",
      "    observation.state: min_max\n",
      "  output_normalization_modes:\n",
      "    action: min_max\n",
      "  vision_backbone: resnet18\n",
      "  crop_shape:\n",
      "  - 52\n",
      "  - 52\n",
      "  crop_is_random: true\n",
      "  pretrained_backbone_weights: null\n",
      "  use_group_norm: true\n",
      "  spatial_softmax_num_keypoints: 32\n",
      "  down_dims:\n",
      "  - 512\n",
      "  - 1024\n",
      "  - 2048\n",
      "  kernel_size: 5\n",
      "  n_groups: 8\n",
      "  diffusion_step_embed_dim: 128\n",
      "  use_film_scale_modulation: true\n",
      "  noise_scheduler_type: DDPM\n",
      "  num_train_timesteps: 100\n",
      "  beta_schedule: squaredcos_cap_v2\n",
      "  beta_start: 0.0001\n",
      "  beta_end: 0.02\n",
      "  prediction_type: epsilon\n",
      "  clip_sample: true\n",
      "  clip_sample_range: 1.0\n",
      "  num_inference_steps: null\n",
      "  do_mask_loss_for_padding: false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import lerobot\n",
    "from lerobot.common.datasets.lerobot_dataset import LeRobotDataset\n",
    "from lerobot.common.datasets.factory import make_dataset\n",
    "\n",
    "\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "# context initialization\n",
    "with initialize(version_base=None, config_path=\"../configs\", job_name=\"test_app\"):\n",
    "    cfg = compose(config_name=\"default\")\n",
    "    print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('/home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000041-ddae63f6f61c40f3ab97629cc2728834-301.npz'), PosixPath('/home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000020-f1d8b1d44fb34249800393d080d4b2c0-301.npz'), PosixPath('/home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000019-27e20f1e5ca542d7bc7dc98d33aeb7f1-70.npz'), PosixPath('/home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000031-469b3b5ac0014e98a56dd56cf328b89d-62.npz'), PosixPath('/home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000026-282d51313d674b469f44f4527957abd3-132.npz'), PosixPath('/home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000036-5fdc796bb96445f18591238b305c5965-301.npz'), PosixPath('/home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000025-a4635fbb3a0146c29e05e31e82fe4710-60.npz'), PosixPath('/home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000022-3fe86bf582ca489681d9c90f651c7450-32.npz'), PosixPath('/home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000013-47be2614a4a141ef886de96272b3f848-83.npz'), PosixPath('/home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000015-cdff8801ee2b4f31bff137861ce81cae-218.npz'), PosixPath('/home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000019-b824e9c2ee324309ab4a60fec0c753cd-57.npz'), PosixPath('/home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000023-3258336c055449779c0b810033e429cb-39.npz'), PosixPath('/home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000027-3633edc7a0774c13a83f66a257a23c94-40.npz'), PosixPath('/home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000039-e9ecb0e114e641ebb2843dca409a1981-68.npz'), PosixPath('/home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000028-75bea66a5c2c4fa4833beaf61529b28f-28.npz'), PosixPath('/home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000033-d105f977ae554c309866a27cc170d896-55.npz'), PosixPath('/home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000019-e2ef874f39a644c79bbfdd6983ea7551-72.npz'), PosixPath('/home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000013-d338ef19744c443692395037d5d6097e-44.npz'), PosixPath('/home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000027-f82e91f8fdf64e748d00ace07393f8d8-87.npz'), PosixPath('/home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000040-3ee1cf86b03148108e2dd5a5c63aa9b4-87.npz'), PosixPath('/home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000040-573d1d08b531460fa915e3005f65f201-73.npz'), PosixPath('/home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000014-6a1af6f8b4a54c569443faae50e55424-84.npz'), PosixPath('/home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000027-0696ca682e0d40068668294b3fe2bcbb-30.npz'), PosixPath('/home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000011-63ecf7b65c3b4a7bb85ed95297198147-140.npz'), PosixPath('/home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000030-3f6aea272f454a038c9d9676ec6461bc-79.npz'), PosixPath('/home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000023-196f15f459fc47c381be71b5c53a831e-301.npz'), PosixPath('/home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000033-028b52d0891a4c42a956b00bd23ab7d9-64.npz'), PosixPath('/home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000013-59336ccee68a49cba209f9c6f362bdbe-55.npz'), PosixPath('/home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000018-d29ca1de23564ec79790c66b147159df-97.npz'), PosixPath('/home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000017-0e72203a58544753a4a984630f98f23e-50.npz'), PosixPath('/home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000036-a7db0fcfc37c4662a73a2d5fb4b7a675-57.npz'), PosixPath('/home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000016-b42156ea4a98498e99e93ef5c11d7dab-90.npz'), PosixPath('/home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000014-9283c91e93d5461d9960373d210d67fa-84.npz'), PosixPath('/home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000023-43a36e748ff543cb9845d459612a628e-42.npz'), PosixPath('/home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000023-55e3fb97f39748788bdc73098555e1b7-52.npz'), PosixPath('/home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000033-6fb893dec14c438bbd78c51db5c5484c-47.npz'), PosixPath('/home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000043-1df3756fab4c4d9c9a1709c56a32b760-103.npz'), PosixPath('/home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000031-99fe88216332462fbfcd6bf6a103b5a0-175.npz'), PosixPath('/home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000034-dc9709764de6410492d28de34dac53fc-301.npz'), PosixPath('/home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000028-abd6b914d1b14444898dd0b94cb0df97-32.npz'), PosixPath('/home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000038-d14e95695ec942ef8b0ddfc5ae16e47a-163.npz'), PosixPath('/home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000036-1e624f1db1fd43b591ebb1c6b8a9e475-44.npz'), PosixPath('/home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000022-9e363fe6b9914e33b785cb4be591a02f-94.npz'), PosixPath('/home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000044-3705644eb2754d03b3bc96c39a692ec4-148.npz'), PosixPath('/home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000040-721f48ffe09641c4abc005d05f08c6ea-62.npz'), PosixPath('/home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000028-7400940190c747989fa51acdb1c660a0-301.npz'), PosixPath('/home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000012-ccc02a021a2d47789ca14cb9b07bdafc-133.npz'), PosixPath('/home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000030-68ff3532559a47f6b3783ad2b42f691e-91.npz'), PosixPath('/home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000017-81c5933329f74509a0e509cfad901b80-76.npz'), PosixPath('/home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000018-19d0edad68584006892948523a58b976-47.npz')]\n",
      "pixels (301, 64, 64, 3)\n",
      "state (301, 5)\n",
      "image (301, 64, 64, 3)\n",
      "is_first (301,)\n",
      "is_last (301,)\n",
      "is_terminal (301,)\n",
      "reward (301,)\n",
      "discount (301,)\n",
      "action (301, 2)\n",
      "logprob (301,)\n"
     ]
    }
   ],
   "source": [
    "# get the path to the dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "env_name = 'pusht' # 'pinpad' # 'robosuite'\n",
    "\n",
    "# base_path = Path(f\"~/workspace/lerobot/local/{env_name}/original\").expanduser()\n",
    "# base_path = Path(f\"~/workspace/fastrl/logs/HD_pinpad_four_1/a\").expanduser()\n",
    "imi = 7\n",
    "AI = True\n",
    "\n",
    "def get_files(env_name, imi, AI=False):\n",
    "    if AI:\n",
    "        base_path = Path(f\"~/workspace/fastrl/logs/AD_pusht_{imi}/\").expanduser()\n",
    "        out_dir = Path(f\"~/workspace/lerobot/local/{env_name}/A{imi}\").expanduser()\n",
    "    else:\n",
    "        base_path = Path(f\"~/workspace/fastrl/logs/HD_pusht_{imi}/\").expanduser()\n",
    "        out_dir = Path(f\"~/workspace/lerobot/local/{env_name}/{imi}\").expanduser()\n",
    "\n",
    "# list all the files in the dataset\n",
    "    folders = list(base_path.glob(\"*\"))\n",
    "\n",
    "    files = []\n",
    "    for f in folders:\n",
    "        files.extend((base_path / f).glob(\"*\"))\n",
    "    return files, out_dir\n",
    "\n",
    "files, out_dir = get_files(env_name, imi, AI=AI)\n",
    "\n",
    "print(files)\n",
    "\n",
    "# print the keys\n",
    "data = np.load(files[0])\n",
    "# convert to a dictionary NOTE: this is necessary to make the arrays writeable for some reason\n",
    "data = dict(data)\n",
    "for k,v in data.items():\n",
    "    print(k, v.shape)\n",
    "\n",
    "# print(\"Setting last is_terminal to true\")\n",
    "# data[\"is_terminal\"][-1] = True; data['is_last'][-1] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000041-ddae63f6f61c40f3ab97629cc2728834-301.npz\n",
      "Processing /home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000020-f1d8b1d44fb34249800393d080d4b2c0-301.npz\n",
      "Processing /home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000019-27e20f1e5ca542d7bc7dc98d33aeb7f1-70.npz\n",
      "Processing /home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000031-469b3b5ac0014e98a56dd56cf328b89d-62.npz\n",
      "Processing /home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000026-282d51313d674b469f44f4527957abd3-132.npz\n",
      "Processing /home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000036-5fdc796bb96445f18591238b305c5965-301.npz\n",
      "Processing /home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000025-a4635fbb3a0146c29e05e31e82fe4710-60.npz\n",
      "Processing /home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000022-3fe86bf582ca489681d9c90f651c7450-32.npz\n",
      "Processing /home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000013-47be2614a4a141ef886de96272b3f848-83.npz\n",
      "Processing /home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000015-cdff8801ee2b4f31bff137861ce81cae-218.npz\n",
      "Processing /home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000019-b824e9c2ee324309ab4a60fec0c753cd-57.npz\n",
      "Processing /home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000023-3258336c055449779c0b810033e429cb-39.npz\n",
      "Processing /home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000027-3633edc7a0774c13a83f66a257a23c94-40.npz\n",
      "Processing /home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000039-e9ecb0e114e641ebb2843dca409a1981-68.npz\n",
      "Processing /home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000028-75bea66a5c2c4fa4833beaf61529b28f-28.npz\n",
      "Processing /home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000033-d105f977ae554c309866a27cc170d896-55.npz\n",
      "Processing /home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000019-e2ef874f39a644c79bbfdd6983ea7551-72.npz\n",
      "Processing /home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000013-d338ef19744c443692395037d5d6097e-44.npz\n",
      "Processing /home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000027-f82e91f8fdf64e748d00ace07393f8d8-87.npz\n",
      "Processing /home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000040-3ee1cf86b03148108e2dd5a5c63aa9b4-87.npz\n",
      "Processing /home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000040-573d1d08b531460fa915e3005f65f201-73.npz\n",
      "Processing /home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000014-6a1af6f8b4a54c569443faae50e55424-84.npz\n",
      "Processing /home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000027-0696ca682e0d40068668294b3fe2bcbb-30.npz\n",
      "Processing /home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000011-63ecf7b65c3b4a7bb85ed95297198147-140.npz\n",
      "Processing /home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000030-3f6aea272f454a038c9d9676ec6461bc-79.npz\n",
      "Processing /home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000023-196f15f459fc47c381be71b5c53a831e-301.npz\n",
      "Processing /home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000033-028b52d0891a4c42a956b00bd23ab7d9-64.npz\n",
      "Processing /home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000013-59336ccee68a49cba209f9c6f362bdbe-55.npz\n",
      "Processing /home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000018-d29ca1de23564ec79790c66b147159df-97.npz\n",
      "Processing /home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000017-0e72203a58544753a4a984630f98f23e-50.npz\n",
      "Processing /home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000036-a7db0fcfc37c4662a73a2d5fb4b7a675-57.npz\n",
      "Processing /home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000016-b42156ea4a98498e99e93ef5c11d7dab-90.npz\n",
      "Processing /home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000014-9283c91e93d5461d9960373d210d67fa-84.npz\n",
      "Processing /home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000023-43a36e748ff543cb9845d459612a628e-42.npz\n",
      "Processing /home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000023-55e3fb97f39748788bdc73098555e1b7-52.npz\n",
      "Processing /home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000033-6fb893dec14c438bbd78c51db5c5484c-47.npz\n",
      "Processing /home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000043-1df3756fab4c4d9c9a1709c56a32b760-103.npz\n",
      "Processing /home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000031-99fe88216332462fbfcd6bf6a103b5a0-175.npz\n",
      "Processing /home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000034-dc9709764de6410492d28de34dac53fc-301.npz\n",
      "Processing /home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000028-abd6b914d1b14444898dd0b94cb0df97-32.npz\n",
      "Processing /home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000038-d14e95695ec942ef8b0ddfc5ae16e47a-163.npz\n",
      "Processing /home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000036-1e624f1db1fd43b591ebb1c6b8a9e475-44.npz\n",
      "Processing /home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000022-9e363fe6b9914e33b785cb4be591a02f-94.npz\n",
      "Processing /home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000044-3705644eb2754d03b3bc96c39a692ec4-148.npz\n",
      "Processing /home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000040-721f48ffe09641c4abc005d05f08c6ea-62.npz\n",
      "Processing /home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000028-7400940190c747989fa51acdb1c660a0-301.npz\n",
      "Processing /home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000012-ccc02a021a2d47789ca14cb9b07bdafc-133.npz\n",
      "Processing /home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000030-68ff3532559a47f6b3783ad2b42f691e-91.npz\n",
      "Processing /home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000017-81c5933329f74509a0e509cfad901b80-76.npz\n",
      "Processing /home/james/workspace/fastrl/logs/AD_pusht_7/final_eps/20240802T000018-19d0edad68584006892948523a58b976-47.npz\n",
      "pixels (5252, 64, 64, 3)\n",
      "state (5252, 5)\n",
      "image (5252, 64, 64, 3)\n",
      "is_first (5252,)\n",
      "is_last (5252,)\n",
      "is_terminal (5252,)\n",
      "reward (5252,)\n",
      "reward 44.0\n",
      "is_terminal 50\n",
      "is_last 44\n",
      "discount (5252,)\n",
      "reward 44.0\n",
      "is_terminal 50\n",
      "is_last 44\n",
      "action (5252, 2)\n",
      "reward 44.0\n",
      "is_terminal 50\n",
      "is_last 44\n",
      "logprob (5252,)\n",
      "reward 44.0\n",
      "is_terminal 50\n",
      "is_last 44\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import torch\n",
    "import einops\n",
    "import shutil\n",
    "from PIL import Image as PILImage\n",
    "import cv2\n",
    "\n",
    "from lerobot.common.datasets.push_dataset_to_hub.utils import concatenate_episodes, save_images_concurrently\n",
    "from lerobot.common.datasets.compute_stats import compute_stats\n",
    "from lerobot.scripts.push_dataset_to_hub import save_meta_data\n",
    "from lerobot.common.datasets.video_utils import VideoFrame, encode_video_frames\n",
    "from lerobot.common.datasets.utils import hf_transform_to_torch\n",
    "from datasets import Dataset, Features, Image, Sequence, Value\n",
    "\n",
    "def to_hf_dataset(data_dict, video):\n",
    "    features = {}\n",
    "\n",
    "    if video:\n",
    "        features[\"observation.image\"] = VideoFrame()\n",
    "    else:\n",
    "        features[\"observation.image\"] = Image()\n",
    "\n",
    "    features[\"observation.state\"] = Sequence(\n",
    "        length=data_dict[\"observation.state\"].shape[1], feature=Value(dtype=\"float32\", id=None)\n",
    "    )\n",
    "    features[\"action\"] = Sequence(\n",
    "        length=data_dict[\"action\"].shape[1], feature=Value(dtype=\"float32\", id=None)\n",
    "    )\n",
    "    features[\"episode_index\"] = Value(dtype=\"int64\", id=None)\n",
    "    features[\"frame_index\"] = Value(dtype=\"int64\", id=None)\n",
    "    features[\"timestamp\"] = Value(dtype=\"float32\", id=None)\n",
    "    features[\"next.reward\"] = Value(dtype=\"float32\", id=None)\n",
    "    features[\"next.done\"] = Value(dtype=\"bool\", id=None)\n",
    "    features[\"index\"] = Value(dtype=\"int64\", id=None)\n",
    "    # TODO(rcadene): add success\n",
    "    # features[\"next.success\"] = Value(dtype='bool', id=None)\n",
    "\n",
    "    hf_dataset = Dataset.from_dict(data_dict, features=Features(features))\n",
    "    hf_dataset.set_transform(hf_transform_to_torch)\n",
    "    return hf_dataset\n",
    "\n",
    "def files_to_data_dict(files):\n",
    "    data_dicts = []\n",
    "    for data_fn in files:\n",
    "        print(f\"Processing {data_fn}\")\n",
    "        data = np.load(data_fn)\n",
    "        data = dict(data); \n",
    "        data[\"is_terminal\"][-1] = True\n",
    "        data_dicts.append(data)\n",
    "    big_data_dict = {}\n",
    "    for k in data_dicts[0].keys():\n",
    "        big_data_dict[k] = np.concatenate([d[k] for d in data_dicts], axis=0)\n",
    "        print(k, big_data_dict[k].shape)\n",
    "        if 'reward' in big_data_dict:\n",
    "            for kk in ['reward', 'is_terminal', 'is_last']:\n",
    "                print(f\"{kk} {sum(big_data_dict[kk])}\")\n",
    "    return big_data_dict\n",
    "\n",
    "big_data_dict = files_to_data_dict(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = big_data_dict['image'][100]\n",
    "# from matplotlib import pyplot as plt\n",
    "# # img = np.random.random((64, 64, 3))\n",
    "# for img in big_data_dict['image'][:100]:\n",
    "#     plt.imshow(img, interpolation='nearest')\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fastrl_to_hf(big_data_dict, out_dir):\n",
    "    video = False; fps = 20; video_path = None; debug = False\n",
    "    ep_dicts = []\n",
    "    episode_data_index = {\"from\": [], \"to\": []}\n",
    "\n",
    "    id_from = 0\n",
    "    id_to = 0\n",
    "    ep_idx = 0\n",
    "    data = big_data_dict\n",
    "    total_frames = data[\"action\"].shape[0]\n",
    "# for i in tqdm.tqdm(range(total_frames)):\n",
    "    for i in range(total_frames):\n",
    "        id_to += 1\n",
    "\n",
    "        if not data[\"is_terminal\"][i]:\n",
    "            continue\n",
    "\n",
    "    # print(\"found terminal step\")\n",
    "\n",
    "        num_frames = id_to - id_from\n",
    "\n",
    "        image = torch.tensor(data[\"image\"][id_from:id_to])\n",
    "    # image = einops.rearrange(image, \"b h w c -> b h w c\")\n",
    "    # image = einops.rearrange(image, \"b c h w -> b h w c\")\n",
    "        state = torch.tensor(data[\"state\"][id_from:id_to, :2]) if (\"state\" in data) else torch.zeros(num_frames, 1)\n",
    "    # state = torch.tensor(data[\"vector_state\"][id_from:id_to]) if (\"vector_state\" in data) else torch.zeros(num_frames, 1)\n",
    "        action = (torch.tensor(data[\"action\"][id_from:id_to]) + 1) * 256\n",
    "    # action = torch.tensor(data[\"action\"][id_from:id_to])\n",
    "    # TODO(rcadene): we have a missing last frame which is the observation when the env is done\n",
    "    # it is critical to have this frame for tdmpc to predict a \"done observation/state\"\n",
    "    # next_image = torch.tensor(data[\"next_observations\"][\"rgb\"][id_from:id_to])\n",
    "    # next_state = torch.tensor(data[\"next_observations\"][\"state\"][id_from:id_to])\n",
    "        next_reward = torch.tensor(data[\"reward\"][id_from:id_to])\n",
    "        next_done = torch.tensor(data[\"is_terminal\"][id_from:id_to])\n",
    "\n",
    "        ep_dict = {}\n",
    "\n",
    "        imgs_array = [x.numpy() for x in image]\n",
    "        img_key = \"observation.image\"\n",
    "        if video:\n",
    "        # save png images in temporary directory\n",
    "            tmp_imgs_dir = out_dir / \"tmp_images\"\n",
    "            tmp_imgs_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            for i in range(len(imgs_array)):\n",
    "                img = PILImage.fromarray(imgs_array[i])\n",
    "                img.save(str(tmp_imgs_dir / f\"frame_{i:06d}.png\"), quality=100)\n",
    "\n",
    "        # encode images to a mp4 video\n",
    "            fname = f\"{img_key}_episode_{ep_idx:06d}.mp4\"\n",
    "            video_path = out_dir / \"videos\" / fname\n",
    "            encode_video_frames(tmp_imgs_dir, video_path, fps)\n",
    "\n",
    "        # clean temporary images directory\n",
    "            shutil.rmtree(tmp_imgs_dir)\n",
    "\n",
    "        # store the reference to the video frame\n",
    "            ep_dict[img_key] = [{\"path\": f\"videos/{fname}\", \"timestamp\": i / fps} for i in range(num_frames)]\n",
    "        else:\n",
    "        # ep_dict[img_key] = [PILImage.fromarray(x) for x in imgs_array]\n",
    "            ep_dict[img_key] = imgs_array\n",
    "\n",
    "        ep_dict[\"observation.state\"] = state\n",
    "        ep_dict[\"action\"] = action\n",
    "        ep_dict[\"episode_index\"] = torch.tensor([ep_idx] * num_frames, dtype=torch.int64)\n",
    "        ep_dict[\"frame_index\"] = torch.arange(0, num_frames, 1)\n",
    "        ep_dict[\"timestamp\"] = torch.arange(0, num_frames, 1) / fps\n",
    "    # ep_dict[\"next.observation.image\"] = next_image\n",
    "    # ep_dict[\"next.observation.state\"] = next_state\n",
    "        ep_dict[\"next.reward\"] = next_reward\n",
    "        ep_dict[\"next.done\"] = next_done\n",
    "        ep_dicts.append(ep_dict)\n",
    "\n",
    "        episode_data_index[\"from\"].append(id_from)\n",
    "        episode_data_index[\"to\"].append(id_from + num_frames)\n",
    "\n",
    "        id_from = id_to\n",
    "        ep_idx += 1\n",
    "\n",
    "    # process first episode only\n",
    "        if debug:\n",
    "            break\n",
    "    if len(ep_dicts) == 0:\n",
    "        print(\"No terminal step found in the dataset\")\n",
    "    else:\n",
    "        data_dict = concatenate_episodes(ep_dicts)\n",
    "        data_dict, episode_data_index\n",
    "\n",
    "        for k,v in data_dict.items():\n",
    "            print(k, v.shape if hasattr(v, 'shape') else len(v))\n",
    "\n",
    "        hf_dataset = to_hf_dataset(data_dict, video)\n",
    "\n",
    "        info = {\"fps\": fps, \"video\": video}\n",
    "\n",
    "        if video_path: \n",
    "            print(f\"video path: {video_path}\")\n",
    "        lerobot_dataset = LeRobotDataset.from_preloaded(\n",
    "            repo_id=env_name,\n",
    "            hf_dataset=hf_dataset,\n",
    "            episode_data_index=episode_data_index,\n",
    "            info=info,\n",
    "            videos_dir=video_path,\n",
    "            )\n",
    "\n",
    "\n",
    "        hf_dataset = hf_dataset.with_format(None)  # to remove transforms that cant be saved\n",
    "        hf_dataset.save_to_disk(str(out_dir / \"train\"))\n",
    "    print(lerobot_dataset)\n",
    "    stats = compute_stats(lerobot_dataset, batch_size=16, num_workers=1)\n",
    "    save_meta_data(info, stats, episode_data_index, out_dir / \"meta_data\")\n",
    "    return stats\n",
    "\n",
    "# stats = fastrl_to_hf(big_data_dict, out_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find files for 4_nonzero AI True\n",
      "Could not find files for 4_nonzero AI False\n"
     ]
    }
   ],
   "source": [
    "# imis = [4, 5, 6, 7, 9, 10] if AI else [3,4,5,6,7,8,9,10]\n",
    "imis = ['4_nozero']\n",
    "for ai_tag in [True, False]:\n",
    "    for imi in imis:\n",
    "        files, out_dir = get_files(env_name, imi, AI=ai_tag)\n",
    "        if files:\n",
    "            big_data_dict = files_to_data_dict(files)\n",
    "            print(f\"Attempting to write to {out_dir}\")\n",
    "            stats = fastrl_to_hf(big_data_dict, out_dir)\n",
    "            for k,v in stats.items():\n",
    "                print(k, v)\n",
    "        else: print(f\"Could not find files for {imi} AI {ai_tag}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from datasets import load_dataset, load_from_disk\n",
    "# loaded_dataset = load_from_disk(str(out_dir / \"train\"))\n",
    "\n",
    "# dataloader = torch.utils.data.DataLoader(\n",
    "#     loaded_dataset,\n",
    "#     num_workers=1,\n",
    "#     batch_size=2,\n",
    "#     shuffle=False,\n",
    "# )\n",
    "\n",
    "# batch = next(iter(dataloader))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
