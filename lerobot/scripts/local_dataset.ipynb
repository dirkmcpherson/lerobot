{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resume: false\n",
      "device: cuda\n",
      "use_amp: false\n",
      "seed: 100000\n",
      "dataset_repo_id: lerobot/pusht\n",
      "video_backend: pyav\n",
      "training:\n",
      "  offline_steps: 200000\n",
      "  num_workers: 4\n",
      "  batch_size: 64\n",
      "  eval_freq: 10000\n",
      "  log_freq: 200\n",
      "  save_checkpoint: true\n",
      "  save_freq: 100000\n",
      "  online_steps: 0\n",
      "  online_rollout_n_episodes: 1\n",
      "  online_rollout_batch_size: 1\n",
      "  online_steps_between_rollouts: 1\n",
      "  online_sampling_ratio: 0.5\n",
      "  online_env_seed: null\n",
      "  online_buffer_capacity: null\n",
      "  online_buffer_seed_size: 0\n",
      "  do_online_rollout_async: false\n",
      "  image_transforms:\n",
      "    enable: false\n",
      "    max_num_transforms: 3\n",
      "    random_order: false\n",
      "    brightness:\n",
      "      weight: 1\n",
      "      min_max:\n",
      "      - 0.8\n",
      "      - 1.2\n",
      "    contrast:\n",
      "      weight: 1\n",
      "      min_max:\n",
      "      - 0.8\n",
      "      - 1.2\n",
      "    saturation:\n",
      "      weight: 1\n",
      "      min_max:\n",
      "      - 0.5\n",
      "      - 1.5\n",
      "    hue:\n",
      "      weight: 1\n",
      "      min_max:\n",
      "      - -0.05\n",
      "      - 0.05\n",
      "    sharpness:\n",
      "      weight: 1\n",
      "      min_max:\n",
      "      - 0.8\n",
      "      - 1.2\n",
      "  grad_clip_norm: 10\n",
      "  lr: 0.0001\n",
      "  lr_scheduler: cosine\n",
      "  lr_warmup_steps: 500\n",
      "  adam_betas:\n",
      "  - 0.95\n",
      "  - 0.999\n",
      "  adam_eps: 1.0e-08\n",
      "  adam_weight_decay: 1.0e-06\n",
      "  delta_timestamps:\n",
      "    observation.image: '[i / ${fps} for i in range(1 - ${policy.n_obs_steps}, 1)]'\n",
      "    observation.state: '[i / ${fps} for i in range(1 - ${policy.n_obs_steps}, 1)]'\n",
      "    action: '[i / ${fps} for i in range(1 - ${policy.n_obs_steps}, 1 - ${policy.n_obs_steps}\n",
      "      + ${policy.horizon})]'\n",
      "  drop_n_last_frames: 7\n",
      "eval:\n",
      "  n_episodes: 50\n",
      "  batch_size: 50\n",
      "  use_async_envs: false\n",
      "wandb:\n",
      "  enable: true\n",
      "  disable_artifact: false\n",
      "  entity: jambotime\n",
      "  project: diffusion_pusht\n",
      "  notes: ''\n",
      "fps: 10\n",
      "env:\n",
      "  name: pusht\n",
      "  task: PushT-v0\n",
      "  image_size: 96\n",
      "  state_dim: 5\n",
      "  action_dim: 2\n",
      "  fps: ${fps}\n",
      "  episode_length: 300\n",
      "  gym:\n",
      "    obs_type: pixels_state\n",
      "    render_mode: rgb_array\n",
      "    visualization_width: 384\n",
      "    visualization_height: 384\n",
      "    observation_width: 96\n",
      "    observation_height: 96\n",
      "    force_sparse: false\n",
      "    display_cross: false\n",
      "override_dataset_stats:\n",
      "  observation.image:\n",
      "    mean:\n",
      "    - - - 0.5\n",
      "    - - - 0.5\n",
      "    - - - 0.5\n",
      "    std:\n",
      "    - - - 0.5\n",
      "    - - - 0.5\n",
      "    - - - 0.5\n",
      "  action:\n",
      "    min:\n",
      "    - 0.0\n",
      "    - 0.0\n",
      "    max:\n",
      "    - 512.0\n",
      "    - 512.0\n",
      "policy:\n",
      "  name: diffusion\n",
      "  n_obs_steps: 2\n",
      "  horizon: 16\n",
      "  n_action_steps: 8\n",
      "  input_shapes:\n",
      "    observation.image:\n",
      "    - 3\n",
      "    - 96\n",
      "    - 96\n",
      "    observation.state:\n",
      "    - ${env.state_dim}\n",
      "  output_shapes:\n",
      "    action:\n",
      "    - ${env.action_dim}\n",
      "  input_normalization_modes:\n",
      "    observation.image: mean_std\n",
      "    observation.state: min_max\n",
      "  output_normalization_modes:\n",
      "    action: min_max\n",
      "  vision_backbone: resnet18\n",
      "  crop_shape:\n",
      "  - 84\n",
      "  - 84\n",
      "  crop_is_random: true\n",
      "  pretrained_backbone_weights: null\n",
      "  use_group_norm: true\n",
      "  spatial_softmax_num_keypoints: 32\n",
      "  down_dims:\n",
      "  - 512\n",
      "  - 1024\n",
      "  - 2048\n",
      "  kernel_size: 5\n",
      "  n_groups: 8\n",
      "  diffusion_step_embed_dim: 128\n",
      "  use_film_scale_modulation: true\n",
      "  noise_scheduler_type: DDPM\n",
      "  num_train_timesteps: 100\n",
      "  beta_schedule: squaredcos_cap_v2\n",
      "  beta_start: 0.0001\n",
      "  beta_end: 0.02\n",
      "  prediction_type: epsilon\n",
      "  clip_sample: true\n",
      "  clip_sample_range: 1.0\n",
      "  num_inference_steps: null\n",
      "  do_mask_loss_for_padding: false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import lerobot\n",
    "from lerobot.common.datasets.lerobot_dataset import LeRobotDataset\n",
    "from lerobot.common.datasets.factory import make_dataset\n",
    "\n",
    "\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "# context initialization\n",
    "with initialize(version_base=None, config_path=\"../configs\", job_name=\"test_app\"):\n",
    "    cfg = compose(config_name=\"default\")\n",
    "    print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/257_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/304_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/237_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/253_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/269_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/132_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/275_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/143_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/121_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/329_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/128_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/240_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/176_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/303_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/280_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/318_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/256_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/181_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/252_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/306_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/179_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/327_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/263_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/164_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/158_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/235_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/160_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/284_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/258_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/168_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/277_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/173_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/259_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/242_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/317_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/244_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/251_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/267_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/146_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/319_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/331_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/274_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/273_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/238_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/234_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/149_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/172_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/250_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/290_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/151_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/255_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/279_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/232_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/243_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/125_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/330_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/129_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/236_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/167_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/126_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/161_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/305_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/130_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/166_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/245_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/297_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/276_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/157_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/148_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/175_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/262_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/325_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/131_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/261_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/239_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/283_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/156_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/286_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/247_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/328_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/265_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/332_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/333_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/138_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/299_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/246_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/233_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/171_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/301_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/334_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/316_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/335_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/122_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/321_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/266_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/308_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/278_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/113_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/137_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/309_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/124_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/260_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/249_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/281_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/139_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/311_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/298_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/248_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/326_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/154_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/162_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/165_pp_pp.npz'), PosixPath('/home/j/workspace/fastrl/logs/HD_ros_54/eps/302_pp_pp.npz')]\n",
      "is_first (295,)\n",
      "is_last (295,)\n",
      "reward (295,)\n",
      "action (295, 5)\n",
      "state (295, 4)\n",
      "joint_states (295, 7)\n",
      "is_terminal (295,)\n",
      "image_top (295, 96, 96)\n",
      "image_bottom (295, 96, 96)\n",
      "discount (295,)\n",
      "logprob (295,)\n",
      "frame_timestamp (0,)\n"
     ]
    }
   ],
   "source": [
    "# get the path to the dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "env_name = 'ros' # 'pusht' # 'pinpad' # 'robosuite'\n",
    "\n",
    "# base_path = Path(f\"~/workspace/lerobot/local/{env_name}/original\").expanduser()\n",
    "# base_path = Path(f\"~/workspace/fastrl/logs/HD_pinpad_four_1/a\").expanduser()\n",
    "imi = 54\n",
    "AI = False\n",
    "tdmpc = False\n",
    "USE_BOTTOM_IMAGE = True\n",
    "\n",
    "def get_files(env_name, imi, AI=False, tdmpc=False, resize=False):\n",
    "    if tdmpc:\n",
    "        bp = f\"~/workspace/fastrl/logs/demonstrations/TDMPC_pusht_HD_{imi}_sparse/\"\n",
    "        od = f\"~/workspace/lerobot/local/{env_name}/tdmpc{imi}\"\n",
    "        assert not AI\n",
    "    else:    \n",
    "        if AI:\n",
    "            bp = f\"~/workspace/fastrl/logs/AD_pusht_{imi}/\"\n",
    "            od = f\"~/workspace/lerobot/local/{env_name}/A{imi}\"\n",
    "        else:\n",
    "            bp = f\"~/workspace/fastrl/logs/HD_ros_{imi}/\"\n",
    "            od = f\"~/workspace/lerobot/local/{env_name}/{imi}\"\n",
    "\n",
    "    if resize:\n",
    "        od = od + \"_96x96\"\n",
    "\n",
    "    base_path = Path(bp).expanduser()\n",
    "    out_dir = Path(od).expanduser()\n",
    "\n",
    "    # print(base_path)\n",
    "# list all the files in the dataset\n",
    "    folders = list(base_path.glob(\"*\"))\n",
    "\n",
    "    files = []\n",
    "    for f in folders:\n",
    "        if not str(f).endswith(\"eps\"): continue # only grab demonstrations\n",
    "        files.extend((base_path / f).glob(\"*\"))\n",
    "    return files, out_dir\n",
    "\n",
    "files, out_dir = get_files(env_name, imi, AI=AI, tdmpc=tdmpc)\n",
    "\n",
    "print(files)\n",
    "\n",
    "# print the keys\n",
    "data = np.load(files[0])\n",
    "# convert to a dictionary NOTE: this is necessary to make the arrays writeable for some reason\n",
    "data = dict(data)\n",
    "for k,v in data.items():\n",
    "    print(k, v.shape)\n",
    "\n",
    "# print(\"Setting last is_terminal to true\")\n",
    "# data[\"is_terminal\"][-1] = True; data['is_last'][-1] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAGdCAYAAABO2DpVAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAGZRJREFUeJzt3XuMVOX9+PHP4sqIhQUVEChX64UiQlWUbrXf2kK1lFg1TWMMTRGtjXZtJVijtKnIH3ZJmpja1qC1Kk3UYm0KWm8UL0CtgoBSQRtERd0qiJWwC1RXZZ/fH8b5dbkosz57md3XKzmJc86ZPc9zdhzemZ2ZU5FSSgEAkEG39h4AANB5CAsAIBthAQBkIywAgGyEBQCQjbAAALIRFgBANsICAMimsq0P2NTUFG+88Ub06tUrKioq2vrwAEALpJRi+/btMWjQoOjWbd+vS7R5WLzxxhsxZMiQtj4sAJBBXV1dDB48eJ/b2zwsevXqFREfDqyqqqqtDw8AtEBDQ0MMGTKk+O/4vrR5WHz054+qqiphAQBl5pPexuDNmwBANsICAMhGWAAA2QgLACAbYQEAZCMsAIBshAUAkI2wAACyERYAQDbCAgDIpqSwuOaaa6KioqLZMnLkyNYaGwBQZkq+Vsixxx4bDz/88P//AZVtfrkRAKCDKrkKKisrY8CAAa0xFgCgzJX8HosNGzbEoEGD4ogjjogpU6bEa6+99rH7NzY2RkNDQ7MFAOicKlJKaX93fvDBB2PHjh1xzDHHxKZNm2L27Nnx+uuvx7p16/Z5ffZrrrkmZs+evcf6+vp6l02HLmr4Vfc3u/3KnMntNBJgfzU0NETv3r0/8d/vksJid9u2bYthw4bFddddFxdeeOFe92lsbIzGxsZmAxsyZIiwgC5MWED52d+w+FTvvOzTp08cffTR8eKLL+5zn0KhEIVC4dMcBgAoE5/qeyx27NgRL730UgwcODDXeACAMlZSWPzkJz+JpUuXxiuvvBJPPPFEnHPOOXHAAQfEeeed11rjAwDKSEl/Cvn3v/8d5513Xrz99tvRr1+/OPXUU2P58uXRr1+/1hofAFBGSgqL+fPnt9Y4AIBOwLVCAIBshAUAkI2wAACyERYAQDbCAgDIRlgAANkICwAgG2EBAGQjLACAbIQFAJCNsAAAshEWAEA2wgIAyEZYAADZCAsAIBthAQBkIywAgGyEBQCQjbAAALIRFgBANsICAMhGWAAA2QgLACAbYQEAZCMsAIBshAUAkI2wAACyERYAQDbCAgDIRlgAANkICwAgG2EBAGQjLACAbIQFAJCNsAAAshEWAEA2wgIAyEZYAADZCAsAIBthAQBkIywAgGyEBQCQjbAAALIRFgBANsICAMhGWAAA2QgLACAbYQEAZCMsAIBshAUAkI2wAACyERYAQDbCAgDIRlgAANkICwAgG2EBAGQjLACAbIQFAJCNsAAAshEWAEA2nyos5syZExUVFTF9+vRMwwEAylmLw2LlypVx0003xZgxY3KOBwAoYy0Kix07dsSUKVPi5ptvjkMOOST3mACAMtWisKipqYnJkyfHxIkTP3HfxsbGaGhoaLYAAJ1TZal3mD9/fjz99NOxcuXK/dq/trY2Zs+eXfLAoDMZftX9zW6/MmdyO41k38phjJ9k9zlElOc8oJyV9IpFXV1dXHbZZXHHHXfEQQcdtF/3mTlzZtTX1xeXurq6Fg0UAOj4SnrFYvXq1bFly5Y44YQTiut27doVy5Yti9/+9rfR2NgYBxxwQLP7FAqFKBQKeUYLAHRoJYXFhAkTYu3atc3WTZs2LUaOHBlXXnnlHlEBAHQtJYVFr169YvTo0c3WfeYzn4nDDjtsj/UAQNfjmzcBgGxK/lTI7pYsWZJhGABAZ+AVCwAgG2EBAGQjLACAbIQFAJCNsAAAshEWAEA2wgIAyEZYAADZCAsAIBthAQBkIywAgGyEBQCQjbAAALIRFgBANsICAMhGWAAA2QgLACAbYQEAZCMsAIBshAUAkI2wAACyERYAQDbCAgDIRlgAANkICwAgG2EBAGQjLACAbIQFAJCNsAAAshEWAEA2wgIAyEZYAADZCAsAIBthAQBkIywAgGyEBQCQjbAAALIRFgBANsICAMhGWAAA2QgLACAbYQEAZCMsAIBshAUAkI2wAACyERYAQDbCAgDIRlgAANkICwAgG2EBAGQjLACAbIQFAJCNsAAAshEWAEA2wgIAyEZYAADZCAsAIBthAQBkIywAgGxKCou5c+fGmDFjoqqqKqqqqqK6ujoefPDB1hobAFBmSgqLwYMHx5w5c2L16tWxatWq+NrXvhZnnXVWPPfcc601PgCgjFSWsvOZZ57Z7Pa1114bc+fOjeXLl8exxx6bdWAAQPkpKSz+165du+Luu++OnTt3RnV19T73a2xsjMbGxuLthoaGlh4SAOjgSg6LtWvXRnV1dbz77rvRs2fPWLBgQYwaNWqf+9fW1sbs2bM/1SChnAy/6v4Od/xX5kxut2O19Hzsfr/WmsP+2p95tPcYW6KjnWfKX8mfCjnmmGNizZo1sWLFirjkkkti6tSp8fzzz+9z/5kzZ0Z9fX1xqaur+1QDBgA6rpJfsejevXsceeSRERFx4oknxsqVK+P666+Pm266aa/7FwqFKBQKn26UAEBZ+NTfY9HU1NTsPRQAQNdV0isWM2fOjEmTJsXQoUNj+/btceedd8aSJUti0aJFrTU+AKCMlBQWW7Zsie9973uxadOm6N27d4wZMyYWLVoUX//611trfABAGSkpLG655ZbWGgcA0Am4VggAkI2wAACyERYAQDbCAgDIRlgAANkICwAgG2EBAGQjLACAbIQFAJCNsAAAshEWAEA2wgIAyEZYAADZCAsAIBthAQBkIywAgGyEBQCQjbAAALIRFgBANsICAMhGWAAA2QgLACAbYQEAZCMsAIBshAUAkI2wAACyERYAQDbCAgDIRlgAANkICwAgG2EBAGQjLACAbIQFAJCNsAAAshEWAEA2wgIAyEZYAADZCAsAIBthAQBkIywAgGyEBQCQjbAAALIRFgBANsICAMhGWAAA2QgLACAbYQEAZCMsAIBshAUAkI2wAACyERYAQDbCAgDIRlgAANkICwAgG2EBAGQjLACAbIQFAJCNsAAAshEWAEA2JYVFbW1tnHTSSdGrV6/o379/nH322bF+/frWGhsAUGZKCoulS5dGTU1NLF++PBYvXhzvv/9+nH766bFz587WGh8AUEYqS9n5oYceanZ73rx50b9//1i9enX83//9X9aBAQDlp6Sw2F19fX1ERBx66KH73KexsTEaGxuLtxsaGj7NIQGADqzFYdHU1BTTp0+PU045JUaPHr3P/Wpra2P27NktPQxd3PCr7t9j3StzJrfDSPJq6bz2dr+ubH/Ox+77lOPjZ38eLy3dpyXHgo/T4k+F1NTUxLp162L+/Pkfu9/MmTOjvr6+uNTV1bX0kABAB9eiVywuvfTSuO+++2LZsmUxePDgj923UChEoVBo0eAAgPJSUliklOJHP/pRLFiwIJYsWRIjRoxorXEBAGWopLCoqamJO++8M+65557o1atXbN68OSIievfuHT169GiVAQIA5aOk91jMnTs36uvr47TTTouBAwcWl7vuuqu1xgcAlJGS/xQCALAvrhUCAGQjLACAbIQFAJCNsAAAshEWAEA2wgIAyEZYAADZCAsAIBthAQBkIywAgGyEBQCQjbAAALIRFgBANsICAMhGWAAA2QgLACAbYQEAZCMsAIBshAUAkI2wAACyERYAQDbCAgDIRlgAANkICwAgG2EBAGQjLACAbIQFAJCNsAAAshEWAEA2wgIAyEZYAADZCAsAIBthAQBkIywAgGyEBQCQjbAAALIRFgBANsICAMhGWAAA2QgLACAbYQEAZCMsAIBshAUAkI2wAACyERYAQDbCAgDIRlgAANkICwAgG2EBAGQjLACAbIQFAJCNsAAAshEWAEA2wgIAyEZYAADZCAsAIBthAQBkIywAgGyEBQCQjbAAALIpOSyWLVsWZ555ZgwaNCgqKipi4cKFrTAsAKAclRwWO3fujLFjx8YNN9zQGuMBAMpYZal3mDRpUkyaNKk1xgIAlLmSw6JUjY2N0djYWLzd0NDQ2ocEANpJq4dFbW1tzJ49u7UPQxsaftX9e6x7Zc7kdjt+ax57b3Nty2PlmltLzllL596W56wl9uc855pDS39Oa/5+WiLX46cl99vbffZn7m35nLQ/cj0W2vv5d3+0+qdCZs6cGfX19cWlrq6utQ8JALSTVn/FolAoRKFQaO3DAAAdgO+xAACyKfkVix07dsSLL75YvL1x48ZYs2ZNHHrooTF06NCsgwMAykvJYbFq1ar46le/Wrw9Y8aMiIiYOnVqzJs3L9vAAIDyU3JYnHbaaZFSao2xAABlznssAIBshAUAkI2wAACyERYAQDbCAgDIRlgAANkICwAgG2EBAGQjLACAbIQFAJCNsAAAshEWAEA2wgIAyEZYAADZCAsAIBthAQBkIywAgGyEBQCQjbAAALIRFgBANsICAMhGWAAA2QgLACAbYQEAZCMsAIBshAUAkI2wAACyERYAQDbCAgDIRlgAANkICwAgG2EBAGQjLACAbIQFAJCNsAAAshEWAEA2wgIAyEZYAADZCAsAIBthAQBkIywAgGyEBQCQjbAAALIRFgBANsICAMhGWAAA2QgLACAbYQEAZCMsAIBshAUAkI2wAACyERYAQDbCAgDIRlgAANkICwAgG2EBAGQjLACAbIQFAJCNsAAAsmlRWNxwww0xfPjwOOigg2L8+PHx1FNP5R4XAFCGSg6Lu+66K2bMmBGzZs2Kp59+OsaOHRtnnHFGbNmypTXGBwCUkZLD4rrrrouLLroopk2bFqNGjYobb7wxDj744Lj11ltbY3wAQBmpLGXn9957L1avXh0zZ84sruvWrVtMnDgxnnzyyb3ep7GxMRobG4u36+vrIyKioaGhJeOlA2hq/O8e61rr97m3Y7XVsff3+K1p97nlGs/ezll7znV/xtOaY851njvrz/mkn7s3LX2eyPV772j/xrTm77Ct5vrRcVJKH79jKsHrr7+eIiI98cQTzdZfccUV6eSTT97rfWbNmpUiwmKxWCwWSydY6urqPrYVSnrFoiVmzpwZM2bMKN5uamqKrVu3xmGHHRYVFRXZjtPQ0BBDhgyJurq6qKqqyvZzy0lXPwfm37XnH+EcdPX5RzgHrTn/lFJs3749Bg0a9LH7lRQWffv2jQMOOCDefPPNZuvffPPNGDBgwF7vUygUolAoNFvXp0+fUg5bkqqqqi75YPpfXf0cmH/Xnn+Ec9DV5x/hHLTW/Hv37v2J+5T05s3u3bvHiSeeGI888khxXVNTUzzyyCNRXV1d+ggBgE6l5D+FzJgxI6ZOnRrjxo2Lk08+OX71q1/Fzp07Y9q0aa0xPgCgjJQcFueee2689dZbcfXVV8fmzZvjC1/4Qjz00ENx+OGHt8b49luhUIhZs2bt8WeXrqSrnwPz79rzj3AOuvr8I5yDjjD/ivSJnxsBANg/rhUCAGQjLACAbIQFAJCNsAAAsuk0YdFZL+W+bNmyOPPMM2PQoEFRUVERCxcubLY9pRRXX311DBw4MHr06BETJ06MDRs2NNtn69atMWXKlKiqqoo+ffrEhRdeGDt27GjDWbRcbW1tnHTSSdGrV6/o379/nH322bF+/fpm+7z77rtRU1MThx12WPTs2TO+/e1v7/Elbq+99lpMnjw5Dj744Ojfv39cccUV8cEHH7TlVFpk7ty5MWbMmOKX3VRXV8eDDz5Y3N6Z5743c+bMiYqKipg+fXpxXWc/B9dcc01UVFQ0W0aOHFnc3tnnHxHx+uuvx3e/+9047LDDokePHnHcccfFqlWrits7+/Pg8OHD93gMVFRURE1NTUR0wMdAKdcK6ajmz5+funfvnm699db03HPPpYsuuij16dMnvfnmm+09tE/tgQceSD/72c/SX/7ylxQRacGCBc22z5kzJ/Xu3TstXLgw/fOf/0zf+ta30ogRI9I777xT3Ocb3/hGGjt2bFq+fHn6+9//no488sh03nnntfFMWuaMM85It912W1q3bl1as2ZN+uY3v5mGDh2aduzYUdzn4osvTkOGDEmPPPJIWrVqVfriF7+YvvSlLxW3f/DBB2n06NFp4sSJ6ZlnnkkPPPBA6tu3b5o5c2Z7TKkk9957b7r//vvTCy+8kNavX59++tOfpgMPPDCtW7cupdS55767p556Kg0fPjyNGTMmXXbZZcX1nf0czJo1Kx177LFp06ZNxeWtt94qbu/s89+6dWsaNmxYOv/889OKFSvSyy+/nBYtWpRefPHF4j6d/Xlwy5YtzX7/ixcvThGRHnvssZRSx3sMdIqwOPnkk1NNTU3x9q5du9KgQYNSbW1tO44qv93DoqmpKQ0YMCD98pe/LK7btm1bKhQK6Y9//GNKKaXnn38+RURauXJlcZ8HH3wwVVRUpNdff73Nxp7Lli1bUkSkpUuXppQ+nO+BBx6Y7r777uI+//rXv1JEpCeffDKl9GGcdevWLW3evLm4z9y5c1NVVVVqbGxs2wlkcMghh6Tf//73XWru27dvT0cddVRavHhx+spXvlIMi65wDmbNmpXGjh27121dYf5XXnllOvXUU/e5vSs+D1522WXpc5/7XGpqauqQj4Gy/1PIR5dynzhxYnHdJ13KvbPYuHFjbN68udnce/fuHePHjy/O/cknn4w+ffrEuHHjivtMnDgxunXrFitWrGjzMX9a9fX1ERFx6KGHRkTE6tWr4/333292DkaOHBlDhw5tdg6OO+64Zl/idsYZZ0RDQ0M899xzbTj6T2fXrl0xf/782LlzZ1RXV3epudfU1MTkyZObzTWi6/z+N2zYEIMGDYojjjgipkyZEq+99lpEdI3533vvvTFu3Lj4zne+E/3794/jjz8+br755uL2rvY8+N5778Xtt98eF1xwQVRUVHTIx0DZh8V//vOf2LVr1x7f/Hn44YfH5s2b22lUbeOj+X3c3Ddv3hz9+/dvtr2ysjIOPfTQsjs/TU1NMX369DjllFNi9OjREfHh/Lp3777Hhe12Pwd7O0cfbevo1q5dGz179oxCoRAXX3xxLFiwIEaNGtUl5h4RMX/+/Hj66aejtrZ2j21d4RyMHz8+5s2bFw899FDMnTs3Nm7cGF/+8pdj+/btXWL+L7/8csydOzeOOuqoWLRoUVxyySXx4x//OP7whz9ERNd7Hly4cGFs27Ytzj///IjomP8PtPpl0yGXmpqaWLduXTz++OPtPZQ2dcwxx8SaNWuivr4+/vznP8fUqVNj6dKl7T2sNlFXVxeXXXZZLF68OA466KD2Hk67mDRpUvG/x4wZE+PHj49hw4bFn/70p+jRo0c7jqxtNDU1xbhx4+IXv/hFREQcf/zxsW7durjxxhtj6tSp7Ty6tnfLLbfEpEmTPvHS5e2p7F+xaMml3DuLj+b3cXMfMGBAbNmypdn2Dz74ILZu3VpW5+fSSy+N++67Lx577LEYPHhwcf2AAQPivffei23btjXbf/dzsLdz9NG2jq579+5x5JFHxoknnhi1tbUxduzYuP7667vE3FevXh1btmyJE044ISorK6OysjKWLl0av/71r6OysjIOP/zwTn8OdtenT584+uij48UXX+wSj4GBAwfGqFGjmq37/Oc/X/xzUFd6Hnz11Vfj4Ycfju9///vFdR3xMVD2YdGVL+U+YsSIGDBgQLO5NzQ0xIoVK4pzr66ujm3btsXq1auL+zz66KPR1NQU48ePb/MxlyqlFJdeemksWLAgHn300RgxYkSz7SeeeGIceOCBzc7B+vXr47XXXmt2DtauXdvsiWXx4sVRVVW1xxNWOWhqaorGxsYuMfcJEybE2rVrY82aNcVl3LhxMWXKlOJ/d/ZzsLsdO3bESy+9FAMHDuwSj4FTTjllj4+Yv/DCCzFs2LCI6BrPgx+57bbbon///jF58uTiug75GMj+dtB2MH/+/FQoFNK8efPS888/n37wgx+kPn36NHsHbLnavn17euaZZ9IzzzyTIiJdd9116ZlnnkmvvvpqSunDj1n16dMn3XPPPenZZ59NZ5111l4/ZnX88cenFStWpMcffzwdddRRZfMxq0suuST17t07LVmypNnHrf773/8W97n44ovT0KFD06OPPppWrVqVqqurU3V1dXH7Rx+1Ov3009OaNWvSQw89lPr161cWH7e76qqr0tKlS9PGjRvTs88+m6666qpUUVGR/va3v6WUOvfc9+V/PxWSUuc/B5dffnlasmRJ2rhxY/rHP/6RJk6cmPr27Zu2bNmSUur883/qqadSZWVluvbaa9OGDRvSHXfckQ4++OB0++23F/fp7M+DKX34acehQ4emK6+8co9tHe0x0CnCIqWUfvOb36ShQ4em7t27p5NPPjktX768vYeUxWOPPZYiYo9l6tSpKaUPP2r185//PB1++OGpUCikCRMmpPXr1zf7GW+//XY677zzUs+ePVNVVVWaNm1a2r59ezvMpnR7m3tEpNtuu624zzvvvJN++MMfpkMOOSQdfPDB6ZxzzkmbNm1q9nNeeeWVNGnSpNSjR4/Ut2/fdPnll6f333+/jWdTugsuuCANGzYsde/ePfXr1y9NmDChGBUpde6578vuYdHZz8G5556bBg4cmLp3754++9nPpnPPPbfZdzh09vmnlNJf//rXNHr06FQoFNLIkSPT7373u2bbO/vzYEopLVq0KEXEHvNKqeM9Blw2HQDIpuzfYwEAdBzCAgDIRlgAANkICwAgG2EBAGQjLACAbIQFAJCNsAAAshEWAEA2wgIAyEZYAADZCAsAIJv/B0P+N0botyXzAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "successful_runs_lengths = []\n",
    "for f in files:\n",
    "    # read, convert to a dictionary NOTE: this is necessary to make the arrays writeable for some reason\n",
    "    data = np.load(f); data = dict(data)\n",
    "\n",
    "    # print(len(data['image_top']), np.sum([entry for entry in data['reward'] if entry > 0]), data['reward'][-1])\n",
    "\n",
    "    if data['reward'][-1] > 0:\n",
    "        successful_runs_lengths.append(len(data['reward']) - 1)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(successful_runs_lengths, bins=100, range=(0, 700))\n",
    "\n",
    "CUTOFF = 450"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96 96 3 4 5\n"
     ]
    }
   ],
   "source": [
    "from lerobot.common.datasets.lerobot_dataset import LeRobotDataset, LeRobotDatasetMetadata\n",
    "import shutil\n",
    "repo_id = f\"j/{imi}\"\n",
    "root = Path(f'~/workspace/lerobot/local/ros_{imi}_{CUTOFF}{\"_BOT\" if USE_BOTTOM_IMAGE else \"\"}').expanduser()\n",
    "# root.mkdir(exist_ok=True)\n",
    "shutil.rmtree(root, ignore_errors=True)\n",
    "\n",
    "use_videos = True\n",
    "\n",
    "# h, w, ch = data['image_top'][0].shape\n",
    "img_shape = data['image_top'][0].shape\n",
    "ch = 3\n",
    "h, w = img_shape[:2]\n",
    "\n",
    "state_ndims = data['state'][0].shape[0]\n",
    "action_ndims = data['action'][0].shape[0]\n",
    "\n",
    "print(h, w, ch, state_ndims, action_ndims)\n",
    "\n",
    "features = {\n",
    "    \"observation.image.top\": {\n",
    "        \"dtype\": \"video\" if use_videos else \"image\",\n",
    "        \"shape\": [h, w, ch],\n",
    "        \"names\": ['height', 'width', 'channels'],\n",
    "        \"info\": None},\n",
    "    \"observation.state\": {\n",
    "        \"dtype\": \"float32\",\n",
    "        \"shape\": (state_ndims,),\n",
    "        \"names\": [f's{i}' for i in range(state_ndims)],\n",
    "    },\n",
    "    \"action\": {\n",
    "        \"dtype\": \"float32\",\n",
    "        \"shape\": (action_ndims,),\n",
    "        \"names\": [f'a{i}' for i in range(action_ndims)],\n",
    "    },\n",
    "    \"next.reward\": {\n",
    "        \"dtype\": \"float32\",\n",
    "        \"shape\": (1,),\n",
    "        \"names\": None,\n",
    "    },\n",
    "    \"next.success\": {\n",
    "        \"dtype\": \"bool\",\n",
    "        \"shape\": (1,),\n",
    "        \"names\": None,\n",
    "    },\n",
    "}\n",
    "\n",
    "if USE_BOTTOM_IMAGE:\n",
    "    features[\"observation.image.bottom\"] = {\n",
    "        \"dtype\": \"video\" if use_videos else \"image\",\n",
    "        \"shape\": [h, w, ch],\n",
    "        \"names\": ['height', 'width', 'channels'],\n",
    "        \"info\": None}\n",
    "\n",
    "# metadata = LeRobotDatasetMetadata(repo_id, root, local_files_only=True)\n",
    "dataset = LeRobotDataset.create(\n",
    "    repo_id,\n",
    "    fps=10, # from pusht.yaml\n",
    "    root=root,\n",
    "    use_videos=use_videos,\n",
    "    features=features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 295/295 [00:00<00:00, 3957.62 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1648.06ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping /home/j/workspace/fastrl/logs/HD_ros_54/eps/304_pp_pp.npz due to length 595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 238/238 [00:00<00:00, 3949.20 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1824.40ba/s]\n",
      "Map: 100%|██████████| 353/353 [00:00<00:00, 4013.63 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1707.08ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping /home/j/workspace/fastrl/logs/HD_ros_54/eps/269_pp_pp.npz due to length 1454\n",
      "Skipping /home/j/workspace/fastrl/logs/HD_ros_54/eps/132_pp_pp.npz due to length 519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 326/326 [00:00<00:00, 4017.64 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1858.35ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping /home/j/workspace/fastrl/logs/HD_ros_54/eps/143_pp_pp.npz due to length 1265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 399/399 [00:00<00:00, 3999.88 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1726.05ba/s]\n",
      "Map: 100%|██████████| 345/345 [00:00<00:00, 4043.07 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1621.30ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping /home/j/workspace/fastrl/logs/HD_ros_54/eps/128_pp_pp.npz due to length 457\n",
      "Skipping /home/j/workspace/fastrl/logs/HD_ros_54/eps/240_pp_pp.npz due to length 461\n",
      "Skipping /home/j/workspace/fastrl/logs/HD_ros_54/eps/176_pp_pp.npz due to length 671\n",
      "Skipping /home/j/workspace/fastrl/logs/HD_ros_54/eps/303_pp_pp.npz due to length 664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 184/184 [00:00<00:00, 3892.90 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 2024.28ba/s]\n",
      "Map: 100%|██████████| 433/433 [00:00<00:00, 4044.56 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1478.43ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping /home/j/workspace/fastrl/logs/HD_ros_54/eps/256_pp_pp.npz due to length 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 302/302 [00:00<00:00, 4054.09 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1881.70ba/s]\n",
      "Map: 100%|██████████| 435/435 [00:00<00:00, 4137.53 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1798.59ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping /home/j/workspace/fastrl/logs/HD_ros_54/eps/306_pp_pp.npz due to length 726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 445/445 [00:00<00:00, 4034.68 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1618.17ba/s]\n",
      "Map: 100%|██████████| 366/366 [00:00<00:00, 4153.02 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1743.27ba/s]\n",
      "Map: 100%|██████████| 299/299 [00:00<00:00, 4019.14 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1918.71ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping /home/j/workspace/fastrl/logs/HD_ros_54/eps/164_pp_pp.npz due to length 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 405/405 [00:00<00:00, 3756.97 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1699.47ba/s]\n",
      "Map: 100%|██████████| 264/264 [00:00<00:00, 3899.84 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1019.77ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping /home/j/workspace/fastrl/logs/HD_ros_54/eps/160_pp_pp.npz due to length 485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 305/305 [00:00<00:00, 3592.34 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1439.86ba/s]\n",
      "Map: 100%|██████████| 323/323 [00:00<00:00, 3993.00 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1898.73ba/s]\n",
      "Map: 100%|██████████| 344/344 [00:00<00:00, 4051.56 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1780.26ba/s]\n",
      "Map: 100%|██████████| 247/247 [00:00<00:00, 3827.17 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1818.87ba/s]\n",
      "Map: 100%|██████████| 403/403 [00:00<00:00, 3977.55 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1421.32ba/s]\n",
      "Map: 100%|██████████| 369/369 [00:00<00:00, 4031.42 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1708.47ba/s]\n",
      "Map: 100%|██████████| 276/276 [00:00<00:00, 3919.06 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1504.95ba/s]\n",
      "Map: 100%|██████████| 384/384 [00:00<00:00, 3948.89 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1714.76ba/s]\n",
      "Map: 100%|██████████| 294/294 [00:00<00:00, 3956.69 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1710.56ba/s]\n",
      "Map: 100%|██████████| 403/403 [00:00<00:00, 3936.64 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1590.56ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping /home/j/workspace/fastrl/logs/HD_ros_54/eps/267_pp_pp.npz due to length 526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 417/417 [00:00<00:00, 3968.31 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1665.73ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping /home/j/workspace/fastrl/logs/HD_ros_54/eps/319_pp_pp.npz due to length 743\n",
      "Skipping /home/j/workspace/fastrl/logs/HD_ros_54/eps/331_pp_pp.npz due to length 789\n",
      "Skipping /home/j/workspace/fastrl/logs/HD_ros_54/eps/274_pp_pp.npz due to length 539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 363/363 [00:00<00:00, 3997.77 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1691.93ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping /home/j/workspace/fastrl/logs/HD_ros_54/eps/238_pp_pp.npz due to length 810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 266/266 [00:00<00:00, 3851.05 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 2022.33ba/s]\n",
      "Map: 100%|██████████| 445/445 [00:00<00:00, 4019.63 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1400.90ba/s]\n",
      "Map: 100%|██████████| 272/272 [00:00<00:00, 3972.47 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1662.43ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping /home/j/workspace/fastrl/logs/HD_ros_54/eps/250_pp_pp.npz due to length 983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 104/104 [00:00<00:00, 3794.59 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 2102.41ba/s]\n",
      "Map: 100%|██████████| 435/435 [00:00<00:00, 3993.56 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1700.16ba/s]\n",
      "Map: 100%|██████████| 366/366 [00:00<00:00, 3860.29 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1807.89ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping /home/j/workspace/fastrl/logs/HD_ros_54/eps/279_pp_pp.npz due to length 529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 257/257 [00:00<00:00, 3969.76 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1692.62ba/s]\n",
      "Map: 100%|██████████| 141/141 [00:00<00:00, 3741.95 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1882.54ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping /home/j/workspace/fastrl/logs/HD_ros_54/eps/125_pp_pp.npz due to length 1239\n",
      "Skipping /home/j/workspace/fastrl/logs/HD_ros_54/eps/330_pp_pp.npz due to length 754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 364/364 [00:00<00:00, 3950.13 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1790.91ba/s]\n",
      "Map: 100%|██████████| 195/195 [00:00<00:00, 3866.92 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1893.59ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping /home/j/workspace/fastrl/logs/HD_ros_54/eps/167_pp_pp.npz due to length 556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 351/351 [00:00<00:00, 4000.32 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1794.74ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping /home/j/workspace/fastrl/logs/HD_ros_54/eps/161_pp_pp.npz due to length 467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 349/349 [00:00<00:00, 4010.61 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1748.36ba/s]\n",
      "Map: 100%|██████████| 358/358 [00:00<00:00, 3889.68 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1730.32ba/s]\n",
      "Map: 100%|██████████| 445/445 [00:00<00:00, 3997.73 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1599.05ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping /home/j/workspace/fastrl/logs/HD_ros_54/eps/245_pp_pp.npz due to length 922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 311/311 [00:00<00:00, 3835.11 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 951.95ba/s]\n",
      "Map: 100%|██████████| 403/403 [00:00<00:00, 3751.67 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1461.94ba/s]\n",
      "Map: 100%|██████████| 394/394 [00:00<00:00, 3956.38 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1620.67ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping /home/j/workspace/fastrl/logs/HD_ros_54/eps/148_pp_pp.npz due to length 968\n",
      "Skipping /home/j/workspace/fastrl/logs/HD_ros_54/eps/175_pp_pp.npz due to length 581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 259/259 [00:00<00:00, 3821.52 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1751.28ba/s]\n",
      "Map: 100%|██████████| 412/412 [00:00<00:00, 3918.69 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1769.75ba/s]\n",
      "Map: 100%|██████████| 410/410 [00:00<00:00, 3945.33 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1636.48ba/s]\n",
      "Map: 100%|██████████| 385/385 [00:00<00:00, 4037.98 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1599.66ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping /home/j/workspace/fastrl/logs/HD_ros_54/eps/239_pp_pp.npz due to length 688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 308/308 [00:00<00:00, 3900.02 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1820.44ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping /home/j/workspace/fastrl/logs/HD_ros_54/eps/156_pp_pp.npz due to length 1549\n",
      "Skipping /home/j/workspace/fastrl/logs/HD_ros_54/eps/286_pp_pp.npz due to length 944\n",
      "Skipping /home/j/workspace/fastrl/logs/HD_ros_54/eps/247_pp_pp.npz due to length 515\n",
      "Skipping /home/j/workspace/fastrl/logs/HD_ros_54/eps/328_pp_pp.npz due to length 733\n",
      "Skipping /home/j/workspace/fastrl/logs/HD_ros_54/eps/265_pp_pp.npz due to length 850\n",
      "Skipping /home/j/workspace/fastrl/logs/HD_ros_54/eps/332_pp_pp.npz due to length 678\n",
      "Skipping /home/j/workspace/fastrl/logs/HD_ros_54/eps/333_pp_pp.npz due to length 1092\n",
      "Skipping /home/j/workspace/fastrl/logs/HD_ros_54/eps/138_pp_pp.npz due to length 877\n",
      "Skipping /home/j/workspace/fastrl/logs/HD_ros_54/eps/299_pp_pp.npz due to length 789\n",
      "Skipping /home/j/workspace/fastrl/logs/HD_ros_54/eps/246_pp_pp.npz due to length 709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 253/253 [00:00<00:00, 3988.54 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1880.85ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping /home/j/workspace/fastrl/logs/HD_ros_54/eps/171_pp_pp.npz due to length 519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 435/435 [00:00<00:00, 4054.21 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1579.78ba/s]\n",
      "Map: 100%|██████████| 344/344 [00:00<00:00, 3893.32 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1472.72ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping /home/j/workspace/fastrl/logs/HD_ros_54/eps/316_pp_pp.npz due to length 499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 267/267 [00:00<00:00, 3407.11 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1777.25ba/s]\n",
      "Map: 100%|██████████| 243/243 [00:00<00:00, 3878.04 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1833.17ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping /home/j/workspace/fastrl/logs/HD_ros_54/eps/321_pp_pp.npz due to length 474\n",
      "Skipping /home/j/workspace/fastrl/logs/HD_ros_54/eps/266_pp_pp.npz due to length 493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 371/371 [00:00<00:00, 3968.11 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1683.78ba/s]\n",
      "Map: 100%|██████████| 187/187 [00:00<00:00, 3795.49 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1833.98ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping /home/j/workspace/fastrl/logs/HD_ros_54/eps/113_pp_pp.npz due to length 1141\n",
      "Skipping /home/j/workspace/fastrl/logs/HD_ros_54/eps/137_pp_pp.npz due to length 501\n",
      "Skipping /home/j/workspace/fastrl/logs/HD_ros_54/eps/309_pp_pp.npz due to length 486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 329/329 [00:00<00:00, 4027.56 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1741.10ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping /home/j/workspace/fastrl/logs/HD_ros_54/eps/260_pp_pp.npz due to length 513\n",
      "Skipping /home/j/workspace/fastrl/logs/HD_ros_54/eps/249_pp_pp.npz due to length 839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 263/263 [00:00<00:00, 3928.78 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1758.62ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping /home/j/workspace/fastrl/logs/HD_ros_54/eps/139_pp_pp.npz due to length 525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 382/382 [00:00<00:00, 3987.94 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1738.93ba/s]\n",
      "Map: 100%|██████████| 293/293 [00:00<00:00, 4022.63 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1804.78ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping /home/j/workspace/fastrl/logs/HD_ros_54/eps/248_pp_pp.npz due to length 847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 264/264 [00:00<00:00, 3908.59 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1965.47ba/s]\n",
      "Map: 100%|██████████| 327/327 [00:00<00:00, 4053.71 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1691.93ba/s]\n",
      "Map: 100%|██████████| 333/333 [00:00<00:00, 3929.22 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1813.36ba/s]\n",
      "Map: 100%|██████████| 370/370 [00:00<00:00, 4060.07 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1651.95ba/s]\n",
      "Map: 100%|██████████| 338/338 [00:00<00:00, 4017.37 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1743.27ba/s]\n",
      "Downloading data: 100%|██████████| 65/65 [00:00<00:00, 555254.09files/s]\n",
      "Generating train split: 21446 examples [00:00, 683606.88 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n",
      "WARN: We should be using libsvtav1 for fast encode/decode but JSS is lazy. Change for real implementations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compute mean, min, max: 100%|█████████▉| 2680/2681 [00:33<00:00, 80.31it/s] \n",
      "Compute std: 100%|█████████▉| 2680/2681 [00:29<00:00, 89.64it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean': tensor([ 0.0548, -0.0284,  0.0218,  0.0056,  0.0224]),\n",
       " 'std': tensor([0.3710, 0.3598, 0.2816, 0.1400, 0.2204]),\n",
       " 'max': tensor([0.9000, 0.9000, 0.9000, 0.9000, 0.9000]),\n",
       " 'min': tensor([-0.9000, -0.9000, -0.9000, -0.9000, -0.9000])}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lerobot.common.datasets.utils import DEFAULT_FEATURES\n",
    "\n",
    "mapping = {\n",
    "    'image_top': 'observation.image.top',\n",
    "    'state': 'observation.state',\n",
    "    'action': 'action',\n",
    "    'reward': 'next.reward',\n",
    "}\n",
    "\n",
    "if USE_BOTTOM_IMAGE:\n",
    "    mapping['image_bottom'] = 'observation.image.bottom'\n",
    "\n",
    "\n",
    "for f in files:\n",
    "    # read, convert to a dictionary NOTE: this is necessary to make the arrays writeable for some reason\n",
    "    data = np.load(f); data = dict(data)\n",
    "\n",
    "    if len(data['image_top']) > CUTOFF:\n",
    "        print(f\"Skipping {f} due to length {len(data['image_top'])}\")\n",
    "        continue\n",
    "\n",
    "    nsteps = len(data['image_top'])\n",
    "    for t in range(nsteps):\n",
    "        frame = {}\n",
    "        for local_key, lerobot_key in mapping.items():\n",
    "            if \"image\" in lerobot_key:\n",
    "                # expand the grayscale image to 3 channels\n",
    "                img = data[local_key][t]\n",
    "                if len(img.shape) == 2:\n",
    "                    img = np.stack([img]*3, axis=-1)\n",
    "                frame[lerobot_key] = img\n",
    "            else:\n",
    "                frame[lerobot_key] = data[local_key][t]\n",
    "            # if local_key == 'action': \n",
    "                # frame[lerobot_key] = (frame[lerobot_key] + 1.) * 256 # NOTE: specifically for gym-pusht\n",
    "\n",
    "\n",
    "        frame['next.success'] = data['reward'][t] > 0\n",
    "        dataset.add_frame(frame)\n",
    "\n",
    "    dataset.save_episode(\"Pick up a cup.\", encode_videos=False)\n",
    "dataset.consolidate()\n",
    "dataset.meta.stats['action']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/j/.cache/huggingface/hub/datasets--ros_54_450_BOT')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = root\n",
    "dst = f'~/.cache/huggingface/hub/datasets--ros_{imi}_{CUTOFF}{\"\" if not USE_BOTTOM_IMAGE else \"_BOT\"}'\n",
    "dst = Path(dst).expanduser()\n",
    "\n",
    "if Path(dst).exists():\n",
    "    shutil.rmtree(dst)\n",
    "shutil.copytree(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import torch\n",
    "import einops\n",
    "import shutil\n",
    "from PIL import Image as PILImage\n",
    "import cv2\n",
    "\n",
    "from lerobot.common.datasets.push_dataset_to_hub.utils import concatenate_episodes, save_images_concurrently\n",
    "from lerobot.common.datasets.compute_stats import compute_stats\n",
    "from lerobot.scripts.push_dataset_to_hub import save_meta_data\n",
    "from lerobot.common.datasets.video_utils import VideoFrame, encode_video_frames\n",
    "from lerobot.common.datasets.utils import orhf_transform_to_torch\n",
    "from datasets import Dataset, Features, Image, Sequence, Value\n",
    "\n",
    "def to_hf_dataset(data_dict, video):\n",
    "    features = {}\n",
    "\n",
    "    if video:\n",
    "        features[\"observation.image\"] = VideoFrame()\n",
    "    else:\n",
    "        features[\"observation.image\"] = Image()\n",
    "\n",
    "    features[\"observation.state\"] = Sequence(\n",
    "        length=data_dict[\"observation.state\"].shape[1], feature=Value(dtype=\"float32\", id=None)\n",
    "    )\n",
    "    features[\"action\"] = Sequence(\n",
    "        length=data_dict[\"action\"].shape[1], feature=Value(dtype=\"float32\", id=None)\n",
    "    )\n",
    "    features[\"episode_index\"] = Value(dtype=\"int64\", id=None)\n",
    "    features[\"frame_index\"] = Value(dtype=\"int64\", id=None)\n",
    "    features[\"timestamp\"] = Value(dtype=\"float32\", id=None)\n",
    "    features[\"next.reward\"] = Value(dtype=\"float32\", id=None)\n",
    "    features[\"next.done\"] = Value(dtype=\"bool\", id=None)\n",
    "    features[\"index\"] = Value(dtype=\"int64\", id=None)\n",
    "    # TODO(rcadene): add success\n",
    "    # features[\"next.success\"] = Value(dtype='bool', id=None)\n",
    "\n",
    "    hf_dataset = Dataset.from_dict(data_dict, features=Features(features))\n",
    "    hf_dataset.set_transform(hf_transform_to_torch)\n",
    "    return hf_dataset\n",
    "\n",
    "def files_to_data_dict(files):\n",
    "    data_dicts = []\n",
    "    for data_fn in files:\n",
    "        print(f\"Processing {data_fn}\", end='...')\n",
    "        data = np.load(data_fn)\n",
    "        data = dict(data); \n",
    "        data[\"is_terminal\"][-1] = True\n",
    "        data_dicts.append(data)\n",
    "    print()\n",
    "    big_data_dict = {}\n",
    "    for k in data_dicts[0].keys():\n",
    "        big_data_dict[k] = np.concatenate([d[k] for d in data_dicts], axis=0)\n",
    "        print(k, big_data_dict[k].shape)\n",
    "        # if 'reward' in big_data_dict:\n",
    "        #     for kk in ['reward', 'is_terminal', 'is_last']:\n",
    "        #         print(f\"\\t{kk} {sum(big_data_dict[kk])}\", end='  ')\n",
    "    return big_data_dict\n",
    "\n",
    "# big_data_dict = files_to_data_dict(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fastrl_to_hf(big_data_dict, out_dir):\n",
    "    video = False; fps = 10; video_path = None; debug = False\n",
    "    ep_dicts = []\n",
    "    episode_data_index = {\"from\": [], \"to\": []}\n",
    "\n",
    "    id_from = 0\n",
    "    id_to = 0\n",
    "    ep_idx = 0\n",
    "    data = big_data_dict\n",
    "    total_frames = data[\"action\"].shape[0]\n",
    "# for i in tqdm.tqdm(range(total_frames)):\n",
    "    for i in range(total_frames):\n",
    "        id_to += 1\n",
    "\n",
    "        if not data[\"is_terminal\"][i]:\n",
    "            continue\n",
    "\n",
    "    # print(\"found terminal step\")\n",
    "\n",
    "        num_frames = id_to - id_from\n",
    "\n",
    "        image = torch.tensor(data[\"image\"][id_from:id_to])\n",
    "    # image = einops.rearrange(image, \"b h w c -> b h w c\")\n",
    "    # image = einops.rearrange(image, \"b c h w -> b h w c\")\n",
    "        state = torch.tensor(data[\"state\"][id_from:id_to, :2]) if (\"state\" in data) else torch.zeros(num_frames, 1)\n",
    "    # state = torch.tensor(data[\"vector_state\"][id_from:id_to]) if (\"vector_state\" in data) else torch.zeros(num_frames, 1)\n",
    "        action = (torch.tensor(data[\"action\"][id_from:id_to]) + 1) * 256\n",
    "    # action = torch.tensor(data[\"action\"][id_from:id_to])\n",
    "    # TODO(rcadene): we have a missing last frame which is the observation when the env is done\n",
    "    # it is critical to have this frame for tdmpc to predict a \"done observation/state\"\n",
    "    # next_image = torch.tensor(data[\"next_observations\"][\"rgb\"][id_from:id_to])\n",
    "    # next_state = torch.tensor(data[\"next_observations\"][\"state\"][id_from:id_to])\n",
    "        next_reward = torch.tensor(data[\"reward\"][id_from:id_to])\n",
    "        next_done = torch.tensor(data[\"is_terminal\"][id_from:id_to])\n",
    "\n",
    "        ep_dict = {}\n",
    "\n",
    "        imgs_array = [x.numpy() for x in image]\n",
    "        img_key = \"observation.image\"\n",
    "        if video:\n",
    "        # save png images in temporary directory\n",
    "            tmp_imgs_dir = out_dir / \"tmp_images\"\n",
    "            tmp_imgs_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            for i in range(len(imgs_array)):\n",
    "                img = PILImage.fromarray(imgs_array[i])\n",
    "                img.save(str(tmp_imgs_dir / f\"frame_{i:06d}.png\"), quality=100)\n",
    "\n",
    "        # encode images to a mp4 video\n",
    "            fname = f\"{img_key}_episode_{ep_idx:06d}.mp4\"\n",
    "            video_path = out_dir / \"videos\" / fname\n",
    "            encode_video_frames(tmp_imgs_dir, video_path, fps)\n",
    "\n",
    "        # clean temporary images directory\n",
    "            shutil.rmtree(tmp_imgs_dir)\n",
    "\n",
    "        # store the reference to the video frame\n",
    "            ep_dict[img_key] = [{\"path\": f\"videos/{fname}\", \"timestamp\": i / fps} for i in range(num_frames)]\n",
    "        else:\n",
    "        # ep_dict[img_key] = [PILImage.fromarray(x) for x in imgs_array]\n",
    "            ep_dict[img_key] = imgs_array\n",
    "\n",
    "        ep_dict[\"observation.state\"] = state\n",
    "        ep_dict[\"action\"] = action\n",
    "        ep_dict[\"episode_index\"] = torch.tensor([ep_idx] * num_frames, dtype=torch.int64)\n",
    "        ep_dict[\"frame_index\"] = torch.arange(0, num_frames, 1)\n",
    "        ep_dict[\"timestamp\"] = torch.arange(0, num_frames, 1) / fps\n",
    "    # ep_dict[\"next.observation.image\"] = next_image\n",
    "    # ep_dict[\"next.observation.state\"] = next_state\n",
    "        ep_dict[\"next.reward\"] = next_reward\n",
    "        ep_dict[\"next.done\"] = next_done\n",
    "        ep_dicts.append(ep_dict)\n",
    "\n",
    "        episode_data_index[\"from\"].append(id_from)\n",
    "        episode_data_index[\"to\"].append(id_from + num_frames)\n",
    "\n",
    "        id_from = id_to\n",
    "        ep_idx += 1\n",
    "\n",
    "    # process first episode only\n",
    "        if debug:\n",
    "            break\n",
    "    if len(ep_dicts) == 0:\n",
    "        print(\"No terminal step found in the dataset\")\n",
    "    else:\n",
    "        for k,v in ep_dicts[0].items():\n",
    "            print(k, ep_dicts[0][k].shape if hasattr(ep_dicts[0][k], 'shape') else len(ep_dicts[0][k]), ep_dicts[-1][k].shape if hasattr(ep_dicts[-1][k], 'shape') else len(ep_dicts[-1][k]))\n",
    "\n",
    "        # convert things to\n",
    "        data_dict = concatenate_episodes(ep_dicts)\n",
    "        data_dict, episode_data_index\n",
    "\n",
    "        for k,v in data_dict.items():\n",
    "            print(k, v.shape if hasattr(v, 'shape') else len(v), type(v))\n",
    "\n",
    "        hf_dataset = to_hf_dataset(data_dict, video)\n",
    "\n",
    "        info = {\"fps\": fps, \"video\": video}\n",
    "\n",
    "        if video_path: \n",
    "            print(f\"video path: {video_path}\")\n",
    "        lerobot_dataset = LeRobotDataset.from_preloaded(\n",
    "            repo_id=env_name,\n",
    "            hf_dataset=hf_dataset,\n",
    "            episode_data_index=episode_data_index,\n",
    "            info=info,\n",
    "            videos_dir=video_path,\n",
    "            )\n",
    "\n",
    "\n",
    "        hf_dataset = hf_dataset.with_format(None)  # to remove transforms that cant be saved\n",
    "        hf_dataset.save_to_disk(str(out_dir / \"train\"))\n",
    "    # print(lerobot_dataset)\n",
    "    stats = compute_stats(lerobot_dataset, batch_size=16, num_workers=1)\n",
    "    save_meta_data(info, stats, episode_data_index, out_dir / \"meta_data\")\n",
    "    return stats\n",
    "\n",
    "# stats = fastrl_to_hf(big_data_dict, out_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def resize_images(bdd):\n",
    "    for k in ['pixels', 'image']:\n",
    "        if k in bdd:\n",
    "            print(f\"Original {k} shape:\", bdd[k].shape)\n",
    "\n",
    "            # Reshape if necessary (assuming the images are in NHWC format)\n",
    "            if bdd[k].shape[-1] != 3:\n",
    "                bdd[k] = np.transpose(bdd[k], (0, 2, 3, 1))\n",
    "        \n",
    "            # Get the original dimensions\n",
    "            n, h, w, c = bdd[k].shape\n",
    "        \n",
    "            # Resize to 96x96\n",
    "            resized = np.zeros((n, 96, 96, c), dtype=bdd[k].dtype)\n",
    "            for i in range(n):\n",
    "                resized[i] = cv2.resize(bdd[k][i], (96, 96), interpolation=cv2.INTER_CUBIC)\n",
    "        \n",
    "        # Update the dictionary with resized images\n",
    "            bdd[k] = resized\n",
    "            \n",
    "            print(f\"Resized {k} shape:\", bdd[k].shape)\n",
    "    else:\n",
    "        print(f\"Key '{k}' not found in big_data_dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imis = [4, 5, 6, 7, 9, 10] if AI else [3,4,5,6,7,8,9,10]\n",
    "RESIZE_TO_96x96 = False\n",
    "imis = [22] #[11, 12, 13, 14]\n",
    "for ai_tag in [True, False]:\n",
    "    for imi in imis:\n",
    "        files, out_dir = get_files(env_name, imi, AI=ai_tag, resize=RESIZE_TO_96x96)\n",
    "        if files:\n",
    "            big_data_dict = files_to_data_dict(files)\n",
    "            if RESIZE_TO_96x96: resize_images(big_data_dict)\n",
    "            print(f\"Attempting to write to {out_dir}\")\n",
    "            stats = fastrl_to_hf(big_data_dict, out_dir)\n",
    "            # for k,v in stats.items():\n",
    "            #     print(k, v)\n",
    "        else: print(f\"Could not find files for {imi} AI {ai_tag}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = False; fps = 20; video_path = None; debug = False\n",
    "ep_dicts = []\n",
    "episode_data_index = {\"from\": [], \"to\": []}\n",
    "\n",
    "id_from = 0\n",
    "id_to = 0\n",
    "ep_idx = 0\n",
    "data = big_data_dict\n",
    "total_frames = data[\"action\"].shape[0]\n",
    "# for i in tqdm.tqdm(range(total_frames)):\n",
    "for i in range(total_frames):\n",
    "    id_to += 1\n",
    "\n",
    "    if not data[\"is_terminal\"][i]:\n",
    "        continue\n",
    "\n",
    "# print(\"found terminal step\")\n",
    "\n",
    "    num_frames = id_to - id_from\n",
    "\n",
    "    image = torch.tensor(data[\"image\"][id_from:id_to])\n",
    "# image = einops.rearrange(image, \"b h w c -> b h w c\")\n",
    "# image = einops.rearrange(image, \"b c h w -> b h w c\")\n",
    "    state = torch.tensor(data[\"state\"][id_from:id_to, :2]) if (\"state\" in data) else torch.zeros(num_frames, 1)\n",
    "# state = torch.tensor(data[\"vector_state\"][id_from:id_to]) if (\"vector_state\" in data) else torch.zeros(num_frames, 1)\n",
    "    action = (torch.tensor(data[\"action\"][id_from:id_to]) + 1) * 256\n",
    "# action = torch.tensor(data[\"action\"][id_from:id_to])\n",
    "# TODO(rcadene): we have a missing last frame which is the observation when the env is done\n",
    "# it is critical to have this frame for tdmpc to predict a \"done observation/state\"\n",
    "# next_image = torch.tensor(data[\"next_observations\"][\"rgb\"][id_from:id_to])\n",
    "# next_state = torch.tensor(data[\"next_observations\"][\"state\"][id_from:id_to])\n",
    "    next_reward = torch.tensor(data[\"reward\"][id_from:id_to])\n",
    "    next_done = torch.tensor(data[\"is_terminal\"][id_from:id_to])\n",
    "\n",
    "    ep_dict = {}\n",
    "\n",
    "    imgs_array = [x.numpy() for x in image]\n",
    "    img_key = \"observation.image\"\n",
    "    if video:\n",
    "    # save png images in temporary directory\n",
    "        tmp_imgs_dir = out_dir / \"tmp_images\"\n",
    "        tmp_imgs_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        for i in range(len(imgs_array)):\n",
    "            img = PILImage.fromarray(imgs_array[i])\n",
    "            img.save(str(tmp_imgs_dir / f\"frame_{i:06d}.png\"), quality=100)\n",
    "\n",
    "    # encode images to a mp4 video\n",
    "        fname = f\"{img_key}_episode_{ep_idx:06d}.mp4\"\n",
    "        video_path = out_dir / \"videos\" / fname\n",
    "        encode_video_frames(tmp_imgs_dir, video_path, fps)\n",
    "\n",
    "    # clean temporary images directory\n",
    "        shutil.rmtree(tmp_imgs_dir)\n",
    "\n",
    "    # store the reference to the video frame\n",
    "        ep_dict[img_key] = [{\"path\": f\"videos/{fname}\", \"timestamp\": i / fps} for i in range(num_frames)]\n",
    "    else:\n",
    "    # ep_dict[img_key] = [PILImage.fromarray(x) for x in imgs_array]\n",
    "        ep_dict[img_key] = imgs_array\n",
    "\n",
    "    ep_dict[\"observation.state\"] = state\n",
    "    ep_dict[\"action\"] = action\n",
    "    ep_dict[\"episode_index\"] = torch.tensor([ep_idx] * num_frames, dtype=torch.int64)\n",
    "    ep_dict[\"frame_index\"] = torch.arange(0, num_frames, 1)\n",
    "    ep_dict[\"timestamp\"] = torch.arange(0, num_frames, 1) / fps\n",
    "# ep_dict[\"next.observation.image\"] = next_image\n",
    "# ep_dict[\"next.observation.state\"] = next_state\n",
    "    ep_dict[\"next.reward\"] = next_reward\n",
    "    ep_dict[\"next.done\"] = next_done\n",
    "    ep_dicts.append(ep_dict)\n",
    "\n",
    "    episode_data_index[\"from\"].append(id_from)\n",
    "    episode_data_index[\"to\"].append(id_from + num_frames)\n",
    "\n",
    "    id_from = id_to\n",
    "    ep_idx += 1\n",
    "\n",
    "# process first episode only\n",
    "    if debug:\n",
    "        break\n",
    "if len(ep_dicts) == 0:\n",
    "    print(\"No terminal step found in the dataset\")\n",
    "else:\n",
    "    for k,v in ep_dicts[0].items():\n",
    "        print(k, ep_dicts[0][k].shape if hasattr(ep_dicts[0][k], 'shape') else len(ep_dicts[0][k]), ep_dicts[-1][k].shape if hasattr(ep_dicts[-1][k], 'shape') else len(ep_dicts[-1][k]))\n",
    "\n",
    "    # convert things to\n",
    "    data_dict = concatenate_episodes(ep_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_dicts[0]['observation.image'][0].shape\n",
    "\n",
    "\n",
    "for f,t in zip(episode_data_index['from'], episode_data_index['to']):\n",
    "    print(f, t, data_dict['action'][f:t].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
